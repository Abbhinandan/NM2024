{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pVlHyob3cOa",
        "outputId": "18309c50-67cc-4b36-9dd2-9c5a0d482760"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "\n",
        "def summarize_article(article_text, max_length=150):\n",
        "    # Load pre-trained model and tokenizer\n",
        "    model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
        "    tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "\n",
        "    # Tokenize the input article\n",
        "    inputs = tokenizer.encode(\"summarize: \" + article_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "\n",
        "    # Generate summary\n",
        "    summary_ids = model.generate(inputs, max_length=max_length, min_length=50, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "\n",
        "    # Decode and return the summary\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "# Example usage:\n",
        "article_text = \"\"\"\n",
        "In the realm of article summarization using generative AI, the future holds promising avenues for advancement and innovation. One such direction involves exploring more sophisticated architectures, such as Transformer-based models like GPT, to further enhance summarization accuracy and context understanding. These advanced architectures can leverage large-scale pre-training and fine-tuning techniques to capture intricate relationships within the text and generate more coherent and informative summaries. Additionally, extending generative AI models to support conditional generation opens up possibilities for tailoring summaries to specific requirements or target audiences, catering to diverse user needs. Another exciting prospect is the integration of GANs with multimodal understanding models, allowing for the summarization of content across various modalities such as text, images, and videos. This multimodal approach can lead to more comprehensive summaries that capture the essence of multimedia content. Furthermore, developing robust evaluation metrics tailored to the nuances of generative AI-generated summaries will be crucial for assessing their quality and effectiveness accurately. As real-time content consumption becomes increasingly prevalent, there is a growing demand for techniques that enable dynamic summarization, providing timely insights as content evolves. Moreover, customizing GAN models for domain-specific summarization tasks, such as in medicine or finance, holds immense potential for delivering relevant and accurate summaries in specialized fields. Integrating interactive features into summarization systems empowers users to provide feedback and refine summaries in real-time, fostering greater engagement and user satisfaction. However, as generative AI continues to evolve, it is imperative to address ethical considerations surrounding AI-generated content, ensuring transparency, fairness, and responsible use of generated summaries to uphold integrity and trust in the summarization process.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "summary = summarize_article(article_text)\n",
        "pprint(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lau2Id6I3mMr",
        "outputId": "7919a382-41e6-4175-95e4-a94bac26d75a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('In the realm of article summarization using generative AI, the future holds '\n",
            " 'promising avenues for advancement and innovation. Transformer-based models '\n",
            " 'like GPT can further enhance summarization accuracy and context '\n",
            " 'understanding. Customizing GAN models for domain-specific summarization '\n",
            " 'tasks, such as in medicine or finance, holds immense potential.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "CKMnH9lENoAY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}